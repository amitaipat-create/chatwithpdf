{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitaipat-create/chatwithpdf/blob/main/Copy_of_RAG_with_PDFs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9a43d1f",
      "metadata": {
        "id": "d9a43d1f"
      },
      "source": [
        "# Retrieval-Augmented Generation (RAG) with PDFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1991ba2",
      "metadata": {
        "id": "e1991ba2"
      },
      "outputs": [],
      "source": [
        "!pip install openai PyPDF2 pdfplumber --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "338cd844",
      "metadata": {
        "id": "338cd844"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from getpass import getpass\n",
        "import os\n",
        "import pdfplumber\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# üîë Enter your OpenAI API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23d50153",
      "metadata": {
        "id": "23d50153"
      },
      "source": [
        "# 2Ô∏è‚É£ Read a PDF using Two Libraries\n",
        "Let's compare how PyPDF2 and pdfplumber extract text from the same document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43f9a73b"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    simple_pdf = filename\n",
        "    print(f\"User uploaded file '{simple_pdf}'\")"
      ],
      "id": "43f9a73b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07c25f74",
      "metadata": {
        "id": "07c25f74"
      },
      "outputs": [],
      "source": [
        "# --- PyPDF2 ---\n",
        "reader = PdfReader(simple_pdf)\n",
        "text_pypdf = \"\"\n",
        "for page in reader.pages:\n",
        "    text_pypdf += page.extract_text()\n",
        "print(\"PyPDF2 Text Sample:\\n\", text_pypdf[:800])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- pdfplumber ---\n",
        "text_plumber = \"\"\n",
        "with pdfplumber.open(simple_pdf) as pdf:\n",
        "    for page in pdf.pages:\n",
        "        text_plumber += page.extract_text()\n",
        "print(\"pdfplumber Text Sample:\\n\", text_plumber[:800])"
      ],
      "metadata": {
        "id": "uDY8mWVqA-K-"
      },
      "id": "uDY8mWVqA-K-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e012e5a6",
      "metadata": {
        "id": "e012e5a6"
      },
      "source": [
        "# ‚úÇÔ∏è 3Ô∏è‚É£ Chunking Strategies\n",
        "\n",
        "Let‚Äôs turn the text into chunks suitable for embedding.\n",
        "We‚Äôll try 3 chunking approaches and compare."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A. Fixed-Size Chunking (Simple)"
      ],
      "metadata": {
        "id": "YvLWj0qMz2UB"
      },
      "id": "YvLWj0qMz2UB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad5402c5",
      "metadata": {
        "id": "ad5402c5"
      },
      "outputs": [],
      "source": [
        "def chunk_text_fixed(text, max_words=200):\n",
        "    words = text.split()\n",
        "    chunks = [\" \".join(words[i:i+max_words]) for i in range(0, len(words), max_words)]\n",
        "    return chunks\n",
        "\n",
        "chunks_fixed = chunk_text_fixed(text_plumber, max_words=10)\n",
        "print(\"Fixed-size chunks:\", len(chunks_fixed))\n",
        "for chunk in chunks_fixed[:3]:\n",
        "    print(chunk[:300])\n",
        "    print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks_fixed = chunk_text_fixed(text_plumber, max_words=20)\n",
        "print(\"Fixed-size chunks:\", len(chunks_fixed))\n",
        "for chunk in chunks_fixed[:3]:\n",
        "    print(chunk[:300])\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "bLM2pvyzCXMQ"
      },
      "id": "bLM2pvyzCXMQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Pros: simple, consistent sizes\n",
        "\n",
        "‚ö†Ô∏è Cons: breaks sentences or paragraphs"
      ],
      "metadata": {
        "id": "UB_YcVZvz9PD"
      },
      "id": "UB_YcVZvz9PD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B. Overlapping Chunking\n",
        "\n",
        "Preserves continuity between chunks ‚Äî useful for context consistency."
      ],
      "metadata": {
        "id": "Cf84H2ta0BQU"
      },
      "id": "Cf84H2ta0BQU"
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text_overlap(text, max_words=200, overlap=50):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), max_words - overlap):\n",
        "        chunk = \" \".join(words[i:i + max_words])\n",
        "        chunks.append(chunk)\n",
        "    return chunks\n",
        "\n",
        "chunks_overlap = chunk_text_overlap(text_plumber, 5, 2)\n",
        "print(\"Overlapping chunks:\", len(chunks_overlap))\n",
        "for chunk in chunks_overlap[:3]:\n",
        "    print(chunk[:300])\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "yrEcfHMN0UQW"
      },
      "id": "yrEcfHMN0UQW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks_overlap = chunk_text_overlap(text_plumber, 10, 3)\n",
        "print(\"Overlapping chunks:\", len(chunks_overlap))\n",
        "for chunk in chunks_overlap[:3]:\n",
        "    print(chunk[:300])\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "uad5IL1OCukA"
      },
      "id": "uad5IL1OCukA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Pros: smoother retrieval, less context loss\n",
        "\n",
        "‚ö†Ô∏è Cons: more total chunks (more embeddings = higher cost)"
      ],
      "metadata": {
        "id": "bz9vbcKy0Jcw"
      },
      "id": "bz9vbcKy0Jcw"
    },
    {
      "cell_type": "markdown",
      "id": "97a7d38a",
      "metadata": {
        "id": "97a7d38a"
      },
      "source": [
        "## C. Sentence-Based Chunking\n",
        "\n",
        "Groups sentences instead of raw word counts ‚Äî produces more semantically coherent pieces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33e1666b",
      "metadata": {
        "id": "33e1666b"
      },
      "outputs": [],
      "source": [
        "from nltk import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def chunk_by_sentences(text, max_sentences=5):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = [\" \".join(sentences[i:i+max_sentences]) for i in range(0, len(sentences), max_sentences)]\n",
        "    return chunks\n",
        "\n",
        "chunks_sentence = chunk_by_sentences(text_plumber, max_sentences=3)\n",
        "print(\"Sentence-based chunks:\", len(chunks_sentence))\n",
        "for chunk in chunks_sentence[:3]:\n",
        "    print(\"###########CHUNK###########\")\n",
        "    print(chunk)\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks_sentence = chunk_by_sentences(text_plumber, max_sentences=5)\n",
        "print(\"Sentence-based chunks:\", len(chunks_sentence))\n",
        "for chunk in chunks_sentence[:3]:\n",
        "    print(chunk)\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "54H7-pzaDE4t"
      },
      "id": "54H7-pzaDE4t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Pros: natural breaks in meaning\n",
        "\n",
        "‚ö†Ô∏è Cons: variable chunk lengths; not ideal for every embedding model"
      ],
      "metadata": {
        "id": "1PCnVHY80gVw"
      },
      "id": "1PCnVHY80gVw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üßÆ 4Ô∏è‚É£ Choose the Best Chunking Strategy\n",
        "\n",
        "For most documents:\n",
        "üëâ Overlapping chunking gives the best tradeoff between context and structure.\n",
        "\n",
        "Let‚Äôs proceed using that."
      ],
      "metadata": {
        "id": "I77Ok1pY0k3e"
      },
      "id": "I77Ok1pY0k3e"
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = chunks_overlap  # you can swap in other methods to compare (chunks_fixed / chunks_overlap / chunks_sentence)\n",
        "for chunk in chunks[:3]:\n",
        "    print(chunk[:300])\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "mGGb4H1J0q9j"
      },
      "id": "mGGb4H1J0q9j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß™ Reflection ‚Äî Experiment\n",
        "\n",
        "Try:\n",
        "\n",
        "Different chunk sizes (100, 300, 500 words).\n",
        "\n",
        "Overlap values (0, 50, 100)."
      ],
      "metadata": {
        "id": "iFNwMiQ61N5R"
      },
      "id": "iFNwMiQ61N5R"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}